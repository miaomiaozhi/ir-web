[url]: http://www1.szu.edu.cn/board/view.asp?id=473664
湾区大数据与人工智能优秀学者论坛将于6月11日线上举行
大数据系统计算技术国家工程实验室　2022/6/8 16:50:00
  “湾区大数据与人工智能优秀学者论坛”将于2022年6月11日上午举行，本次论坛由深圳大学大数据系统计算技术国家工程实验室主办，李坚强教授为论坛主席，朱泽轩教授为组委会主席。论坛邀请了国内外知名院士、优秀学者和青年学者探讨学科领域最新的学术理论和研究热点，旨在聚焦大数据与人工智能领域，关注国际学术前沿和学科热点，激发学术灵感，洽谈职业发展规划，为海内外优秀青年学者提供交流的平台，欢迎广大师生参会。
 一、论坛议程
6月11日 08:30-12:00
时间
报告题目
报告人
08:30-09:00
心脑血管介入手术机器人系统前沿技术开发和挑战
郭书祥 院士
09:00-09:30
脉冲神经网络的动力学与计算
关治洪 教授
09:30-09:55
信息抽取任务中弱监督数据的生成和利用
戴洪良
09:55-10:20
树突状神经元模型的建模与应用
吉君恺
10:20-10:45
计算机系统低能耗研究
李雪亮
10:45-11:10
面向人工智能物联网的轨道及道路交通数据驱动专业化
王恬格
11:10-11:35
静息态脑功能rs-fMRI在不同疾病与状态下的研究
张慧
11:35-12:00
分布式深度学习系统中的高效参数更新策略
张兆瑞
*青年学者报告顺序按姓名首字母顺序排列
二、参会方式
腾讯会议APP（会议号276155146，或扫描下方二维码入会）
三、特邀专家 
   郭书祥
报告内容：
心脑血管介入手术机器人系统前沿技术开发和挑战
近年，手术机器人技术快速发展，规范化的机器人平台成为医生的智能工具，应用于神经介入外科、心脏外科等复杂外科手术中，为患者带来极大福音。
心脑血管介入手术机器人突破人手极限，灵活智能，末端器械采用智能设计原理，充分考虑自由度、刚度和操作力等因素，更有高效主从控制算法、神经网络学习算法的加入，能为手术操作精度保驾护航，实现精准、直观、智能的控制。
本讲座重点就心脑血管介入手术机器人技术和虚拟现实训练系统的开发现状和挑战进行实例介绍，阐述心脑血管介入手术机器人的前沿理论和关键技术。最后分析介入手术机器人在医疗临床领域的广泛应用前景。
 人物介绍：
郭书祥，博士、日本工程院外籍院士、IEEE Fellow, 国家海外高层次人才引进计划教授，教育部 “知名学者奖励计划 ”教授。工业和信息化部 融合医工系统与健康工程重点实验室主任。担任IEEE ICMA国际会议的创始大会主席以及《IJMA (机电一体化和自动化）国际杂志》主编等学术职务。长期从事微机器人技术、血管检查微系统、医疗生物用遥控微操作系统等方面的研究工作。在世界上率先开发出直径 1mm的两种脑血管检查微系统，其所研制的具有3自由度的仿生鱼形微机器人，属世界首创，曾在世界权威杂志 New Scientist 上介绍报道。已发表350余篇论文及专著，并多次获得IEEE国际会议最佳论文奖。拥有40余项机器人和微系统方面的发明专利。郭书祥是在生物医学工程领域，爱思唯尔2021中国高被引学者(Scopus Most Cited Chinese Researchers)。
      关治洪
报告内容：
脉冲神经网络的动力学与计算
人工智能的发展有赖于对生物智能的认识、理解和应用。无疑生物智能离不开神经网络。探索生物神经网络的结构、演化规律和信息处理机制，一直是人们不懈的追求。生物神经网络是通过“脉冲”形式来传递信息的，因此脉冲神经网络更接近真实的生物神经网络。报告将介绍脉冲神经网络的有关研究进展，包括脉冲神经网络的模型、动力学演化性质和自适应学习算法等内容，以及进一步需要解决的问题。
 人物介绍：
关治洪，华中科技大学人工智能与自动化学院教授，博士生导师。1994年在华南理工大学自动化系自控理论及应用专业博士研究生毕业，获博士学位。1994年任教授，1998年任博士生导师，2007年任二级教授，2011年任华中学者领军岗教授。研究兴趣包括脉冲混杂系统、混杂智能系统、网络控制系统、复杂网络与多智能体（机器人）系统、智能电网、神经网络与人工智能。主持2项国家自然科学基金重点项目和多项面上项目等研究。出版“Introduction to Hybrid Intelligent Networks, Springer 2019”等著作3部。研究成果获2005年度教育部自然科学一等奖，2014年度湖北省自然科学一等奖。爱思唯尔(Elsevier)高被引学者（控制与系统工程）。
    四、青年学者
  戴洪良
报告题目：
信息抽取任务中弱监督数据的生成和利用
摘要：
在自然语言处理的信息抽取领域，许多任务面临着因人工标注成本高而导致的训练数据稀缺问题。利用弱监督数据是应对该问题的一个重要方式。我们研究了评价对象和观点词抽取、细粒度实体分类这两个信息抽取任务的弱监督数据生成和利用，它们分别属于抽取和分类两种不同类型的任务。对评价对象和观点词抽取任务，我们提出了一种先用规则自动标注出大量弱监督训练数据，再利用它们结合人工标注数据来提升模型最终效果的新方法。对细粒度实体分类，首先，我们通过引入外部信息以及优化模型结构来更好地利用大量的弱监督数据。其次，提出了一种基于Stacking来综合利用大量弱监督训练数据和少量人工标注数据的方法。最后，提出了一种基于Prompting的新的实体类别标签生成方法。在两个任务上，我们所提出的不同的弱监督数据生成和利用方法都对提升模型最终效果起到了帮助。
  吉君恺
报告题目：
树突状神经元模型的建模与应用
摘要：
我们提出一个全新的树突状神经元模型(Dendritic neural model)。该模型可以模拟大脑神经元的树突可塑性现象，自适应地裁剪冗余的突触和树突分支，来精简自身模型结构。对比于其他人工神经网络，该模型有着更高生物仿真性。同时，精简后的神经元模型可以编译成由比较器，逻辑与，或，非门构建的逻辑电路分类器(Logic circuit classifier)。对比于其他以浮点数计算为主的机器学习算法，该分类器完全以二进制计算，因此有着更快的运算速度和更低的计算功耗。考虑到其可以在FPGS和VLSI等上硬件实现和进行大规模并行计算，该分类器在处理大规模高数据流问题上有着更加明显的性能优势。也为有效解决“冯诺依曼瓶颈”提出全新的思路。
    李雪亮
报告题目：
计算机系统低能耗研究
摘要：
随着物联网、工业4.0的推进，我们将进入“万物皆计算机系统”的时代。计算机系统的能耗优化水平将对全球能耗以及碳排放产生至关重要的影响。而计算机系统的能效优化是一个系统性、跨层次的问题。如何才能实现系统级功耗优化？我们必须在各个层级，包括硬件、体系结构及软件层，实现突破。本报告将从体系结构以及应用软件层面介绍计算机能耗优化的挑战以及研究进展。
    王恬格
报告题目：
面向人工智能物联网的轨道及道路交通数据驱动专业化
摘要：
Artificial Intelligence of Things (AIoT) represents the combination of artificial intelligence (AI) technologies and the internet of things (IoT) infrastructure. It aims to improve human-machine interactions, providing efficient and effective data management and analytics for both individual devices and the overall system. In this talk, I will advocate for data-driven approaches that complete a set of tasks specifically related to rail and road transportation. Examples of AIoT in transportation presented in this talk include track inspection using deep learning vision systems, and traffic safety assessment with the combination of IoT data. Both examples show extra resource saving and high performance beyond the corresponding domain sciences.
    张慧
报告题目：
静息态脑功能rs-fMRI在不同疾病与状态下的研究
摘要：
此次报告选取了个人的三项最具有代表性的研究作为主体内容，其中包括鼻腔吸入式胰岛素对糖尿病病人的大脑功能的影响，携带高风险APOE4基因和正常健康人之间的小世界网络指标与位于海马体的化学递质Glx之间的关联与区别以及大脑功能在嗅觉缺失的长新冠病人的表现。相信我的研究可以与更多的算法技术相结合，为精确的医疗诊断和康复治疗提供进一步帮助。
  张兆瑞
报告题目：
分布式深度学习系统中的高效参数更新策略
摘要：
近些年，随着AI的蓬勃发展，工业界对深度学习模型的准确性需求越来越高，深度学习模型(DNNs)因此变得越来越庞大。工业界和AI应用中产生的大量数据给大型DNN模型带来了机会，可以使大型DNN模型训练到较高的准确性。在现如今大模型和大数据的背景下，单台机器已经无法满足训练需求，因此分布式深度学习系统近些年变成一个很热门的研究领域。分布式深度学习系统是一个交叉学科，它涉及到分布式系统、优化中的分布式优化和随机优化以及机器学习算法等多个研究领域。基于大数据的大模型训练需要消耗很长时间才能获得较高的准确性，这个过程通常需要几天几周，甚至几个月。因此如何让分布式深度学习系统高效地训练变成一个亟待解决的问题。分布式深度学习系统中通信通常会占用很大的时间比重，从而变成深度学习系统的一个瓶颈。此外，训练过程中的梯度误差也会导致训练需要更多次的迭代优化才能使模型收敛，因此梯度误差也是影响训练性能的一个很重要的因素。如何解决这些问题成为了目前研究的热点及难点问题，基于该研究背景，本研究主要是针对分布式训练中如何高效地更新参数，涉及到如何有效的减小通信开销和如何约束梯度误差。
（本文更新于2022/6/8 16:50:00）